<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://thomasmaslow.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://thomasmaslow.github.io/" rel="alternate" type="text/html" /><updated>2023-05-20T16:45:35+02:00</updated><id>https://thomasmaslow.github.io/feed.xml</id><title type="html">DIY Blog</title><subtitle>My personal introduction and story, my interests, and what to expect from my blog.</subtitle><entry><title type="html">A new tool for Postgres database schema migrations</title><link href="https://thomasmaslow.github.io/blog/new-tool-for-postgres-database-schema-migrations" rel="alternate" type="text/html" title="A new tool for Postgres database schema migrations" /><published>2023-04-28T13:25:12+02:00</published><updated>2023-05-08T16:03:02+02:00</updated><id>https://thomasmaslow.github.io/blog/new-tool-for-postgres-database-schema-migrations</id><content type="html" xml:base="https://thomasmaslow.github.io/blog/new-tool-for-postgres-database-schema-migrations"><![CDATA[<p>PostgreSQL is a powerful open-source relational database management system that is used by many developers in a lot of projects around the world. As your application grows and evolves, so will your database schema. Managing schema changes can be a challenging task, but there are tools available that can help simplify the process. One such tool is Schema Guard.</p>

<p><a href="https://www.thomasmaslow.ru/streamline-your-database-schema-management-with-schema-duard.php">Schema Guard</a> is a powerful and flexible database schema migration tool that makes it easy to manage and apply changes to your PostgreSQL schema. With this tool, developers can create and track migration files that describe changes to your database schema. These migration files can be versioned and stored in a source control system, making it easy to collaborate with other developers and ensure consistency across environments.</p>

<p>Let’s look at some examples of how Schema Guard can be used to manage database schema changes. Suppose you want to add a new table to your database schema. You would first create a new migration file that describes the changes you want to make, such as:</p>

<figure class="highlight"><pre><code class="language-sql" data-lang="sql"><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">new_table</span> <span class="p">(</span> <span class="n">id</span> <span class="nb">SERIAL</span> <span class="k">PRIMARY</span> <span class="k">KEY</span><span class="p">,</span> <span class="n">name</span> <span class="nb">TEXT</span> <span class="k">NOT</span> <span class="k">NULL</span><span class="p">,</span> <span class="n">description</span> <span class="nb">TEXT</span> <span class="p">);</span></code></pre></figure>

<p>You would then run the tool to apply the migration, using the following command:</p>

<figure class="highlight"><pre><code class="language-sql" data-lang="sql"><span class="n">rdbm</span> <span class="n">apply</span></code></pre></figure>

<p>This would apply the migration and create the new table in your database schema.</p>

<p>Now, suppose you want to modify an existing table by adding a new column. You would create a new migration file that describes the changes, such as:</p>

<figure class="highlight"><pre><code class="language-sql" data-lang="sql"><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="n">existing_table</span> <span class="k">ADD</span> <span class="k">COLUMN</span> <span class="n">new_column</span> <span class="nb">TEXT</span><span class="p">;</span></code></pre></figure>

<p>And once again, you would run the Schema Guard tool to apply the migration.</p>

<p>Schema Guard also makes it easy to roll back changes if necessary. Suppose you applied a migration that caused problems with your application. You could use the following command to roll back the last applied migration:</p>

<figure class="highlight"><pre><code class="language-sql" data-lang="sql"><span class="n">rdbm</span> <span class="k">rollback</span></code></pre></figure>

<p>This would undo the last applied migration and restore your schema to its previous state.</p>

<p>In addition to its core functionality, Schema Guard also provides a number of features that make it even more powerful and flexible. For example, you can use this tool to generate SQL scripts that can be used to create or modify the schema on a different machine or in a different environment.</p>

<p>Another useful feature of Schema Guard is its ability to detect and prevent conflicts between migration files. If two developers create conflicting migration files, it will detect the conflict and prevent the migrations from being applied until the conflict is resolved.</p>

<p>Overall, Schema Guard is a powerful tool that can help you streamline your database schema management process. By providing a simple and flexible way to manage schema changes, Schema Guard can help you avoid common pitfalls such as inconsistencies and errors in your database schema. Whether you are a seasoned PostgreSQL developer or just getting started, Schema Guard is definitely worth considering for your schema migration needs. By providing a centralized location for tracking and applying changes, Schema Guard can help ensure consistency and reduce errors in your database schema. Whether you’re a seasoned PostgreSQL developer or just getting started, Schema Guard is definitely worth considering for your schema migration needs.</p>]]></content><author><name></name></author><category term="postgres" /><category term="sql" /><category term="database" /><category term="schema" /><category term="migrations" /><category term="postgres" /><category term="sql" /><category term="database" /><category term="schema" /><category term="migrations" /><summary type="html"><![CDATA[New Schema Guard tool to centralize tracking and applying of schema changes.]]></summary></entry><entry><title type="html">Verifying Database Backups with MD5 Checksums</title><link href="https://thomasmaslow.github.io/blog/verifying-database-backups-with-md5-checksums" rel="alternate" type="text/html" title="Verifying Database Backups with MD5 Checksums" /><published>2023-03-23T14:03:34+01:00</published><updated>2023-05-08T19:15:21+02:00</updated><id>https://thomasmaslow.github.io/blog/verifying-database-backups-with-md5-checksums</id><content type="html" xml:base="https://thomasmaslow.github.io/blog/verifying-database-backups-with-md5-checksums"><![CDATA[<p>As someone who has worked with databases, I know how important it is to have reliable backups of your data. However, it’s not enough to simply create backups – you need to verify that they are not corrupted and can be restored in case of a disaster. This is where the MD5 checksum checker tool comes in handy.</p>

<p>The MD5 checksum is a unique value calculated based on the contents of a file. If the file contents are modified, even by a single byte, the MD5 checksum changes. By comparing the MD5 checksums of the source and destination files, you can ensure that the files are identical and not corrupted during the transfer.</p>

<p>While Linux has a built-in md5 command, Windows users need to download and install an MD5 <a href="https://www.fastsum.com/">checksum checker tool</a>, it is the one of the most handy options for Windows. Which offers both a command-line version and a GUI version. The command-line version is free to use, while the GUI version is a commercial product.</p>

<p>To demonstrate how to use the MD5 checksum checker tool for database backups, I’ll walk you through an example scenario. Let’s say you have a database server running on a Windows machine, and you want to create a backup of the database and transfer it to another Windows machine over the network. Here are the steps you can follow:</p>

<p>Create a database backup file using your preferred method (e.g., pg_dump for PostgreSQL databases).</p>

<p>Calculate the MD5 checksum of the backup file using FastSum’s command-line tool. Open a command prompt and navigate to the directory where the backup file is located. Then, enter the following command:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">fsum C:<span class="se">\D</span>ata<span class="se">\*</span>.zip /T:F /R</code></pre></figure>

<p>This will calculate the MD5 checksum of the backup file and display it in the command prompt.</p>

<p>Transfer the backup file to the destination machine using a file transfer protocol such as FTP or rsync.</p>

<p>On the destination machine, calculate the MD5 checksum of the transferred backup file using FastSum’s command-line tool. Open a command prompt and navigate to the directory where the transferred file is located. Then, enter the following command:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">fsum C:<span class="se">\D</span>ata /T:F /R /V</code></pre></figure>

<p>This will calculate the MD5 checksum of the transferred file and display it in the command prompt.</p>

<p>Compare the MD5 checksums of the source and destination files. If they match, it means the backup file was transferred without any corruption. If they don’t match, it means the file was corrupted during the transfer, and you should re-transfer the file.</p>

<p>In addition to using the MD5 checksum checker tool, it’s a good practice to also verify the integrity of your database backups by restoring them to a test environment and checking if the data is intact. However, using the MD5 checksum checker tool is a quick and easy way to ensure that your backups are not corrupted during the transfer.</p>

<p>In conclusion, using an MD5 checksum checker tool like FastSum can help you verify the integrity of your database backups when transferring them over the network. With just a few simple commands, you can calculate the MD5 checksum of your backup files and ensure that they are identical on both the source and destination machines. While Windows users need to download and install an MD5 checksum checker tool, FastSum’s command-line version is free to use and provides an easy way to check the integrity of your database backups.</p>]]></content><author><name></name></author><category term="postgres" /><category term="database" /><category term="pg-dump" /><category term="fastsum" /><category term="fsum" /><category term="md5" /><category term="integrity" /><category term="postgres" /><category term="database" /><category term="pg-dump" /><category term="fastsum" /><category term="fsum" /><category term="md5" /><category term="integrity" /><summary type="html"><![CDATA[My Experience Using MD5 Checksum Tool for Verifying Database Backups.]]></summary></entry><entry><title type="html">Faster Queries, Lower Latency</title><link href="https://thomasmaslow.github.io/blog/faster-queries-lower-latency" rel="alternate" type="text/html" title="Faster Queries, Lower Latency" /><published>2023-03-23T14:03:34+01:00</published><updated>2023-05-10T12:53:35+02:00</updated><id>https://thomasmaslow.github.io/blog/faster-queries-lower-latency</id><content type="html" xml:base="https://thomasmaslow.github.io/blog/faster-queries-lower-latency"><![CDATA[<p>I have notice over the years that proper table design is critical to achieving high performance in a <a href="https://www.postgresql.org/">PostgreSQL</a> database. One of the most important aspects of table design is the proper arrangement of fields. In this article, I will explain how properly arranging fields in a database table can increase the performance of PostgreSQL and provide examples of how to implement this in SQL code.</p>

<p>PostgreSQL is a powerful relational database management system that uses SQL as its primary language. It is known for its robustness, scalability, and flexibility. However, it requires proper configuration and optimization to achieve the best performance. One key aspect of optimization is the arrangement of fields in tables.</p>

<p>When creating a table in PostgreSQL, it is essential to define the fields in a way that makes sense logically and optimizes performance. One best practice is to group fields that are frequently accessed together, such as those used in a single query or transaction. This allows PostgreSQL to read and write data more efficiently, reducing the number of disk I/O operations required.</p>

<p>Another best practice is to use the appropriate data types for each field. Choosing the right data type can help to reduce the amount of disk space used by the table and increase the performance of the database. For example, using a boolean data type instead of a varchar(5) for a field that can only have two values (e.g., true or false) can reduce the size of the table and increase query performance.</p>

<p>One example of how properly arranged fields can improve performance is in the case of a table with many columns, some of which are rarely accessed. In this scenario, it is advisable to move the rarely accessed columns to a separate table to reduce the amount of data that PostgreSQL needs to read and write during query execution. This approach is called vertical partitioning and can significantly improve performance in certain scenarios.</p>

<p>Here’s an example of how to create a table with properly arranged fields in PostgreSQL:</p>

<figure class="highlight"><pre><code class="language-sql" data-lang="sql"><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">example_table</span> <span class="p">(</span> <span class="n">id</span> <span class="nb">SERIAL</span> <span class="k">PRIMARY</span> <span class="k">KEY</span><span class="p">,</span> <span class="n">name</span> <span class="nb">VARCHAR</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span> <span class="k">NOT</span> <span class="k">NULL</span><span class="p">,</span> <span class="n">email</span> <span class="nb">VARCHAR</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span> <span class="k">NOT</span> <span class="k">NULL</span><span class="p">,</span> <span class="n">date_of_birth</span> <span class="nb">DATE</span><span class="p">,</span> <span class="n">is_active</span> <span class="nb">BOOLEAN</span> <span class="k">DEFAULT</span> <span class="k">TRUE</span> <span class="p">);</span></code></pre></figure>

<p>In this example, we have grouped the frequently accessed fields (id, name, email, and is_active) together and used the appropriate data types for each field. We have also added a default value for the is_active field, which can further optimize performance by reducing the amount of data that needs to be written to the table.</p>

<p>Another example of how properly arranged fields can improve performance is by using partial indexes. Partial indexes are a feature in PostgreSQL that allow you to create indexes on a subset of rows in a table. By using a partial index, you can reduce the size of the index and improve query performance.</p>

<p>Here’s an example of how to create a partial index in PostgreSQL:</p>

<figure class="highlight"><pre><code class="language-sql" data-lang="sql"><span class="k">CREATE</span> <span class="k">INDEX</span> <span class="n">example_index</span> <span class="k">ON</span> <span class="n">example_table</span> <span class="p">(</span><span class="n">name</span><span class="p">)</span> <span class="k">WHERE</span> <span class="n">is_active</span> <span class="o">=</span> <span class="k">true</span><span class="p">;</span></code></pre></figure>

<p>In this example, we have created a partial index on the name field where the is_active field is true. This will create a smaller index that only includes the rows where is_active is true, reducing the size of the index and improving query performance.</p>

<p>If you’re going to perform some database schema changes after reading this, you may find useful my article about a tool for <a href="/blog/new-tool-for-postgres-database-schema-migrations">schema migrations</a>.</p>

<p>One of the most important factors in organizing fields is to ensure that the most frequently accessed columns are located at the beginning of the row. When a query is executed, the database must read data from the storage device into memory. By placing the most frequently accessed fields at the beginning of the row, the database can read and return the data more quickly.</p>

<p>For example, let’s consider a table that has 10 columns. The first five columns are accessed more frequently than the remaining five columns. If we arrange the columns so that the first five columns are at the beginning of the row, then the database can retrieve data more efficiently. Here’s an example SQL code to create such a table:</p>

<figure class="highlight"><pre><code class="language-sql" data-lang="sql"><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">my_table</span> <span class="p">(</span> <span class="n">column1</span> <span class="nb">INTEGER</span><span class="p">,</span> <span class="n">column2</span> <span class="nb">TEXT</span><span class="p">,</span> <span class="n">column3</span> <span class="nb">TIMESTAMP</span><span class="p">,</span> <span class="n">column4</span> <span class="nb">INTEGER</span><span class="p">,</span> <span class="n">column5</span> <span class="nb">TEXT</span><span class="p">,</span> <span class="n">column6</span> <span class="nb">TEXT</span><span class="p">,</span> <span class="n">column7</span> <span class="nb">INTEGER</span><span class="p">,</span> <span class="n">column8</span> <span class="nb">TEXT</span><span class="p">,</span> <span class="n">column9</span> <span class="nb">TEXT</span><span class="p">,</span> <span class="n">column10</span> <span class="nb">BOOLEAN</span> <span class="p">);</span></code></pre></figure>

<p>Another important factor to consider when arranging fields is to group related columns together. This is especially important when working with larger tables that have many columns. Grouping related columns together can improve the readability of the table, making it easier to maintain and modify.</p>

<p>For instance, let’s consider a table that stores information about customers, including their name, address, phone number, and email. It makes sense to group all the customer information columns together, as shown in the following example SQL code:</p>

<figure class="highlight"><pre><code class="language-sql" data-lang="sql"><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">customers</span> <span class="p">(</span> <span class="n">customer_id</span> <span class="nb">INTEGER</span><span class="p">,</span> <span class="n">first_name</span> <span class="nb">TEXT</span><span class="p">,</span> <span class="n">last_name</span> <span class="nb">TEXT</span><span class="p">,</span> <span class="n">street_address</span> <span class="nb">TEXT</span><span class="p">,</span> <span class="n">city</span> <span class="nb">TEXT</span><span class="p">,</span> <span class="k">state</span> <span class="nb">TEXT</span><span class="p">,</span> <span class="n">zip_code</span> <span class="nb">TEXT</span><span class="p">,</span> <span class="n">phone_number</span> <span class="nb">TEXT</span><span class="p">,</span> <span class="n">email</span> <span class="nb">TEXT</span> <span class="p">);</span></code></pre></figure>

<p>In addition to organizing columns, it’s important to consider the data types of each column. PostgreSQL has many different data types, each with its own advantages and disadvantages. For example, using a VARCHAR data type instead of TEXT for a column with a limited length can save disk space and improve query performance. Similarly, using a DATE data type instead of TIMESTAMP when the time component is not required can also improve performance.</p>

<p>Here’s an example SQL code to create a table with optimized data types:</p>

<figure class="highlight"><pre><code class="language-sql" data-lang="sql"><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">my_table</span> <span class="p">(</span> <span class="n">column1</span> <span class="nb">INTEGER</span><span class="p">,</span> <span class="n">column2</span> <span class="nb">VARCHAR</span><span class="p">(</span><span class="mi">255</span><span class="p">),</span> <span class="n">column3</span> <span class="nb">DATE</span><span class="p">,</span> <span class="n">column4</span> <span class="nb">BOOLEAN</span> <span class="p">);</span></code></pre></figure>

<p>It looks like the properly arranging fields in a database table is a critical aspect of PostgreSQL optimization. By grouping frequently accessed fields together, using the appropriate data types, and utilizing features like vertical partitioning and partial indexes, you can significantly improve the performance of your database. As a database administrator, it is important to understand these best practices and implement them in your PostgreSQL databases to achieve the best performance possible.</p>]]></content><author><name></name></author><category term="postgres" /><category term="database" /><category term="performance" /><category term="postgres" /><category term="database" /><category term="performance" /><summary type="html"><![CDATA[How Properly Organized Fields Improve PostgreSQL Performance.]]></summary></entry></feed>